{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jojovputtkamer/NLP_WiSe25.26/blob/main/jputt_Processing_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Datasets in Notebooks\n",
        "\n",
        "\n",
        "Created by Sarah Oberbichler [![ORCID](https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png)](https://orcid.org/0000-0002-1031-2759)\n"
      ],
      "metadata": {
        "id": "Z92h4kZjqoBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data to the Notebook\n",
        "\n",
        "In order to access our course data, we clone the course GitHub repository to this notebook. Do do so, run the *git clone* cell below:"
      ],
      "metadata": {
        "id": "b0p9NHUqGPfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/soberbichler/NLP-Course4Humanities_2025.github.io.git"
      ],
      "metadata": {
        "id": "g9WMeLNvG4SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e98083-341e-491e-86a7-cbf6c8b37083"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Course4Humanities_2025.github.io'...\n",
            "remote: Enumerating objects: 1744, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 1744 (delta 86), reused 23 (delta 23), pack-reused 1622 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1744/1744), 83.02 MiB | 30.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1005/1005), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UQpLyh05GMSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "43b32cc4-8d0c-43ee-e891-953c62890072"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'content/datasets/newspaper_lesson.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29354495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Replace 'your_file.xlsx' with the actual path to your Excel file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/datasets/newspaper_lesson.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Display the first few rows of the DataFrame to verify it's loaded correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/datasets/newspaper_lesson.xlsx'"
          ]
        }
      ],
      "source": [
        "# @markdown ##### If you copied the path, find the place where you can add it. Run the code and investigate the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.xlsx' with the actual path to your Excel file.\n",
        "df = pd.read_excel('content/datasets/newspaper_lesson.xlsx')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify it's loaded correctly.\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Investigate your data\n",
        "\n",
        "Now we can investigate the data. First let's check how many rows the excel file has:"
      ],
      "metadata": {
        "id": "TmYFTXPIKeQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the DataFrame\n",
        "\n",
        "print(f\"The DataFrame has {df.shape[0]} rows.\")"
      ],
      "metadata": {
        "id": "YOHIdX7IKNtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only work with one of the column\n",
        "df['paper_title']"
      ],
      "metadata": {
        "id": "dIE9fxvHYKZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of different newspaper titles\n",
        "num_unique_titles = df['paper_title'].nunique()\n",
        "\n",
        "print(f\"There are {num_unique_titles} different paper titles in the dataset.\")"
      ],
      "metadata": {
        "id": "R4VRrXV-hkrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ##### **Exercise 1:** Now find the number of different places of distribution using the same method with the .nunique() function\n",
        "\n",
        "# add your code here"
      ],
      "metadata": {
        "id": "pHOMxQ_wXUNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ##### **Exercise 2:** Find the column with the full text, load the first three rows of this column. Do you remember from the introduction how to find the first three letters in a string. We can use the same method to find the first three rows in a dataframe.\n",
        "\n",
        "# add your code here\n"
      ],
      "metadata": {
        "id": "WfND8IrQYU43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print full text of one row of plainpagefulltext\n",
        "\n",
        "print(df['plainpagefulltext'][0])"
      ],
      "metadata": {
        "id": "_Lk7NmzSaiU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change the size of your DataFrame\n",
        "\n",
        "We can also change the size of a DataFrame. Let's say we want to do some testing with only the first 10 rows of the dataset."
      ],
      "metadata": {
        "id": "9FD4B1_scKO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduce your DataFrame to 10 rows\n",
        "df_short = df[:10]"
      ],
      "metadata": {
        "id": "0QmuubKfcx_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ##### **Exercise 2:** Check if the DataFrame had been reduced to 10 rows\n",
        "\n",
        "#add your code here"
      ],
      "metadata": {
        "id": "zNNyjV43drXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search through your Dataframe\n",
        "\n",
        "We might also want to only works a specific aspect from our dataset. Let's assume, we only want to use newspapers that have been distributed in Berlin."
      ],
      "metadata": {
        "id": "1BM7sPXUjU6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only rows where 'place_of_distribution' is 'Berlin'.\n",
        "df_berlin = df[df['place_of_distribution'].str.contains('Leipzig', na = False)]\n",
        "\n",
        "# Display the filtered DataFrame.\n",
        "df_berlin.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "7pQ2WLETjr7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many rows are these?\n",
        "\n",
        "#add code here"
      ],
      "metadata": {
        "id": "mQqeXQGOk8hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3:\n",
        "\n",
        "Create a new DataFrame where each fulltext contains a specific word. For example \"Katastrophe\"."
      ],
      "metadata": {
        "id": "zDDBXhnLmqu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add your code here:\n",
        "\n"
      ],
      "metadata": {
        "id": "JaVkjnZOqS3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}